meeting with Ludovic 2015-19-11:

- call Tobias:
 - We are on time pressure
 - you'll (Jakob and Tobias) be included in the paper
 - Still want to finished the model, but we need to submit
 - Need to find a way to make it work on many nucleosomes - and use the maximum read length.
 - Will be included in next publication
- Finalize WIKI and TUTORIAL then send to L
- make methylation vs nucleosome score across top 1% called nucleosomes to see methylation drop towards dyad and nucleosome increase
 - Do it as a profile -120;+120 of a dyad
 or
 - as bars if less precise
 - do it on all samples
- Make all samples with occupied/unonccupied CTCF plot 
- extract lambda estimates from mapdamage (high - short overhang) (low - long overhang)
 - Can we correlate that with
 - make a linear model coverage ~ delta s * lambda val
 - check if first peak in methylation is 10-bp periodicity that comes from preference of break for every 10 base pair
 - take the downsampled bam file where the 200bp peak in methylation is still higher than the noise. 10 bp peak might not be noise so some other peak. 
- for nucleosome calls we decided to use delta instead of log-scores

- if long overhang you need less probability of getting a hit per base than for short overhang reads. long overhang samples might have clear CTCF pattern even for low delta s samples.
- download new data from eppie and remember to include MOTA african sample from now on
- PhD plan confirmation together with ludovic


- ideas to later
 - make a model of CTCF binding sites and predict the 50000 whether occupied or unoccupied









- get nucleosome calls from Tobias and liftover to hg19 and use these as test. Hope to see something similar - kris
- scan genome + plus some simple peak-calling - Tobias
- gamma and lambda - Tobias
- get version check of pysam and numpy - kris
- compiling cython to both mac and linux systems - Jakob might have some experience with that
- setup.py + compiling cython if needed
- make R-scripts for plotting for the end-user
- upload example to ftp:
 - /k/ftp-data/OrlandoGroup
 - make a folder and add { TEST.bam, reference genome fasta, yamlfile, bedfile} 

- How do we handle samples we reads that a  100  or above???
- do reservoir sampling for read length (min, max)
- follow your guts - knight - ted talk

- git fork paleomix github
- virtual environment. use that not to cause problems with already existing versions of Paleomix.
- write an email to Ludovic, Jakob, Tobias:
  - an update
  - we don't see the same pattern
  - why do we not see this
  - discard long reads > 100 & only use the start of reads of a 100
    - consider using both ends for 100 reads single ends.
    - for paired-end data, we can use both ends for collapsed reads.
 - do auroch and send to both Ludovic and Bastien - done


- send documentation and example to ludovic



## README for installation, setup and running epiPALEOMIX.
## The pipeline has been tested on debian servers
## put unzip epipaleomix.zip into a folder:
##     .i.e ~/install
## update .profile/.bashrc by write following in terminal:
##        echo "export PYTHONPATH=\$PYTHONPATH:~/install/epipaleomix/" >> ~/.bash_profile
##        or:
##        echo "export PYTHONPATH=\$PYTHONPATH:~/install/epipaleomix/" >> ~/.profile

## CREATE MAKE FILE TEMPLATE
##     # prints to std.out (standard out)
##     ~/install/epipaleomix/epipaleomix/epaleomix.py makefile >  000_makefile.yaml

## EXECUTE:
##         ~/install/epipaleomix/epipaleomix/epaleomix.py mkfile > 003_mkfile.yaml
##         # Fill in the paths/options in 003_mkfile.yaml
##         ~/install/epipaleomix/epipaleomix/epaleomix.py dryrun 003_mkfile.yaml
##         # simple version with 4 cores (default)
##         ~/install/epipaleomix/epipaleomix/epipaleomix.py run 003_mkfile.yaml
##         # defining destination paths and temporary folders:
##         ~/install/epipaleomix/epipaleomix/epipaleomix.py -h  # for help

## TOOLS/PACKAGES required:
## -- Bedtools
## -- Python 2.7:
##         -- Pysam
## -- R:
##         -- ggplot2
##         -- reshape2
##         -- gridExtra
